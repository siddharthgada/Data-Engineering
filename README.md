# Data Engineering

## Data Modeling

### Skills Acquired:
- Relational data modeling with PostgreSQL
- How to create tables and insert data into PostgreSQL
- NoSQL data modeling with Apache Cassandra
- How to create tables and insert data into Apache Cassandra
- The process of database normalization and the normal forms.
- Denormalization and when it should be used.
- Fact vs dimension tables as a concept and how to apply that to our data modeling
- How the star and snowflake schemas use the concepts of fact and dimension tables to make getting value out of the data easier.
- Basics of Distributed Database Design

Proficiencies used: PostgreSQL, Apache Cassandra(CQL), Normalization, Denormalization

### Project 1: NoSQL Databases - Data Modeling with Apache Cassandra
Developed a NoSQL database using Apache Cassandra to model user activity data for a music streaming app. <br>

Skills include:
- Created a NoSQL database using Apache Cassandra
- Developed denormalized tables optimized for a specific set of queries and business needs

Proficiencies used: Python, Apache Cassandra(CQL), Denormalization

## Cloud Data Warehouses

### Skills Acquired:
- Practiced ETL steps from a 3NF database to a Star Schema
- Practiced slicing, dicing, Roll Up and Drill Down operations with OLAP cubes
- Using ETL and ELT techniques
- Using Relational and NoSQL databases in the cloud
- Creating an IAM role and user, security group, S3 bucket, PostgreSQL Database
- Launching a Redshift Cluster
- How to ETL with Redshift
- How to ingest data into Redshift using S3 buckets
- Parallel ETL
- Optimizing Table Design using Distribution Styles

Proficiencies used: SQL, PostgreSQL, AWS Redshift, AWS EC2, AWS S3, AWS IAM, Normalization, Denormalization
